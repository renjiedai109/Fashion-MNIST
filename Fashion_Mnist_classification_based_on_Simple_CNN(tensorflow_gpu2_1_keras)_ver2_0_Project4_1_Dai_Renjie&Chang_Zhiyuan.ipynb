{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_Mnist classification based on Simple CNN(tensorflow-gpu2.1-keras) ver2.0 Project4-1 Dai Renjie&Chang Zhiyuan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4V-wI8JGWM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "class_names = {0: 'T-shirt/top',\n",
        "               1: 'Trouser',\n",
        "               2: 'Pullover',\n",
        "               3: 'Dress',\n",
        "               4: 'Coat',\n",
        "               5: 'Sandal',\n",
        "               6: 'Shirt',\n",
        "               7: 'Sneaker',\n",
        "               8: 'Bag',\n",
        "               9: 'Ankle boot'}\n",
        "mnist_classes = [i for i in range(10)]\n",
        "num_classes = 10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)  \n",
        "train_images = train_images.reshape([-1, 28, 28, 1]) / 255.0\n",
        "test_images = test_images.reshape([-1, 28, 28, 1]) / 255.0\n",
        "\n",
        "\n",
        "def model():\n",
        "\n",
        "\n",
        "    cnn = tf.keras.Sequential()\n",
        "\n",
        "    cnn.add(tf.keras.layers.InputLayer(input_shape=(28,28,1)))\n",
        "\n",
        "    # Normalization\n",
        "    cnn.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # Conv + Maxpooling\n",
        "    cnn.add(tf.keras.layers.Convolution2D(32, (5,5), padding='same', activation='relu'))\n",
        "    cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Dropout\n",
        "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    # Conv + Maxpooling\n",
        "    cnn.add(tf.keras.layers.Convolution2D(64, (3,3), activation='relu'))\n",
        "    cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Dropout\n",
        "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    # Converting 3D feature to 1D feature Vector\n",
        "    cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    cnn.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "    # Dropout\n",
        "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "    # Normalization\n",
        "    cnn.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    cnn.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "    return cnn\n",
        "\n",
        "model().summary()\n",
        "\n",
        "model=model()\n",
        "epochs = 5\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5, validation_split=0.2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('the model\\'s test_loss is {} and test_acc is {}'.format(test_loss, test_acc))\n",
        "\n",
        "\n",
        "show_images = test_images[:20]\n",
        "print(show_images.shape)\n",
        "show_predictions = model.predict(show_images)\n",
        "predict_labels = np.argmax(show_predictions, 1)\n",
        "# \n",
        "plt.figure(figsize=(6,3)) \n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "\n",
        "    plt.imshow(show_images[i, :, :, 0], cmap=plt.cm.binary)\n",
        "    plt.title(class_names[predict_labels[i]])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "test_predictions=model.predict(test_images)\n",
        "cm = confusion_matrix(test_labels, np.argmax(test_predictions,axis=1))\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, np.argmax(test_predictions,axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}